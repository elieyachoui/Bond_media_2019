{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elieyachoui/Bond_media_2019/blob/master/LlamaIndex_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xil8_DI8gIyK",
        "outputId": "9bea0199-7d69-49f9-b7e0-6b237faaea47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'llama_index' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jerryjliu/llama_index.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_UJ1jdIaBsw",
        "outputId": "8d620dbf-bea1-4f51-f033-debe86a2e6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.8.39.post2-py3-none-any.whl (864 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/864.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.3/864.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.5/864.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama_hub\n",
            "  Downloading llama_hub-0.0.34-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tiktoken (from llama-index)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting langchain>=0.0.303 (from llama-index)\n",
            "  Downloading langchain-0.0.309-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Collecting openai>=0.26.4 (from llama-index)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Collecting urllib3<2 (from llama-index)\n",
            "  Downloading urllib3-1.26.17-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.11.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Collecting atlassian-python-api (from llama_hub)\n",
            "  Downloading atlassian_python_api-3.41.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.2/167.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2text (from llama_hub)\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama_hub) (5.9.5)\n",
            "Collecting retrying (from llama_hub)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (4.0.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.303->llama-index)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.40 (from langchain>=0.0.303->llama-index)\n",
            "  Downloading langsmith-0.0.42-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (1.10.13)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting deprecated (from atlassian-python-api->llama_hub)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama_hub) (1.16.0)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama_hub) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama_hub) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama-index) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (1.1.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama-index)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->atlassian-python-api->llama_hub) (1.15.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=0c4a178a5ec924d3ffa5ac63a32896b6405ed936eee4993ab8033cd343f2324c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: urllib3, retrying, mypy-extensions, marshmallow, jsonpointer, html2text, deprecated, typing-inspect, jsonpatch, wikipedia, tiktoken, openai, langsmith, dataclasses-json, langchain, atlassian-python-api, llama-index, llama_hub\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.6\n",
            "    Uninstalling urllib3-2.0.6:\n",
            "      Successfully uninstalled urllib3-2.0.6\n",
            "Successfully installed atlassian-python-api-3.41.2 dataclasses-json-0.6.1 deprecated-1.2.14 html2text-2020.1.16 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.309 langsmith-0.0.42 llama-index-0.8.39.post2 llama_hub-0.0.34 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.1 retrying-1.3.4 tiktoken-0.5.1 typing-inspect-0.9.0 urllib3-1.26.17 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama_hub wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NPFmLmrWhsb1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL1wjI7StrFg"
      },
      "source": [
        "# Data connectors (LlamaHub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bgNV_zwtbO-C"
      },
      "outputs": [],
      "source": [
        "from llama_hub.wikipedia.base import WikipediaReader\n",
        "\n",
        "loader = WikipediaReader()\n",
        "documents = loader.load_data(pages=['Berlin', 'Rome', 'Tokyo', 'Canberra', 'Santiago'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8hSbUjUT4VK"
      },
      "source": [
        "# Basic query functionalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Goo4yvAnTN_5"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "# build an index over these Document objects.\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "# you can query an index with the default QueryEngine\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"How many people live in Berlin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzDGa1dATtyX"
      },
      "outputs": [],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed8v3NF990f6"
      },
      "source": [
        "# Query Multiple Documents:\n",
        "Source: https://gpt-index.readthedocs.io/en/latest/examples/usecases/10q_sub_question.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk9PnvfwCyUz"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vogXg-_Y-DHS"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader, LLMPredictor, ServiceContext, VectorStoreIndex\n",
        "from llama_index.response.pprint_utils import pprint_response\n",
        "from langchain import OpenAI\n",
        "\n",
        "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.query_engine import SubQuestionQueryEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obFzvbnF95mX"
      },
      "outputs": [],
      "source": [
        "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=-1, streaming=True))\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjZyv2CR-MzJ"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvF4mfiyES6W"
      },
      "outputs": [],
      "source": [
        "ls llama_index/docs/examples/data/10q/uber_10q_sept_2022.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtAeoSQF97Rx"
      },
      "outputs": [],
      "source": [
        "march_2022 = SimpleDirectoryReader(input_files=[\"llama_index/docs/examples/data/10q/uber_10q_march_2022.pdf\"]).load_data()\n",
        "june_2022 = SimpleDirectoryReader(input_files=[\"llama_index/docs/examples/data/10q/uber_10q_june_2022.pdf\"]).load_data()\n",
        "sept_2022 = SimpleDirectoryReader(input_files=[\"llama_index/docs/examples/data/10q/uber_10q_sept_2022.pdf\"]).load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw28Y6fu-3wx"
      },
      "outputs": [],
      "source": [
        "march_index = VectorStoreIndex.from_documents(march_2022)\n",
        "june_index = VectorStoreIndex.from_documents(june_2022)\n",
        "sept_index = VectorStoreIndex.from_documents(sept_2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HlBCpeB-4Dt"
      },
      "outputs": [],
      "source": [
        "march_engine = march_index.as_query_engine(similarity_top_k=3)\n",
        "june_engine = june_index.as_query_engine(similarity_top_k=3)\n",
        "sept_engine = sept_index.as_query_engine(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd_bZl8E-5j8"
      },
      "outputs": [],
      "source": [
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=sept_engine,\n",
        "        metadata=ToolMetadata(name='sept_22', description='Provides information about Uber quarterly financials ending September 2022')\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=june_engine,\n",
        "        metadata=ToolMetadata(name='june_22', description='Provides information about Uber quarterly financials ending June 2022')\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=march_engine,\n",
        "        metadata=ToolMetadata(name='march_22', description='Provides information about Uber quarterly financials ending March 2022')\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-6Ro7FN-7q4"
      },
      "outputs": [],
      "source": [
        "# Given a query, this query engine `SubQuestionQueryEngine ` will generate a “query plan”\n",
        "# containing sub-queries against sub-documents before synthesizing the final answer.\n",
        "s_engine = SubQuestionQueryEngine.from_defaults(query_engine_tools=query_engine_tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87T7bQRd-9lA"
      },
      "outputs": [],
      "source": [
        "response = s_engine.query('Analyze Uber revenue growth over the latest two quarter filings')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxDRYtcK--nb"
      },
      "outputs": [],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQaqiYCeIPLP"
      },
      "source": [
        "# Router\n",
        "\n",
        "define a custom router query engine that can route to either a SQL database or a vector database.\n",
        "\n",
        "Source: https://gpt-index.readthedocs.io/en/latest/examples/query_engine/SQLRouterQueryEngine.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NM8XlJ5SL4_"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        "    SQLStructStoreIndex,\n",
        "    SQLDatabase,\n",
        "    WikipediaReader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7eXvL2-SXH6"
      },
      "outputs": [],
      "source": [
        "# Create Database Schema + Test Data\n",
        "# Here we introduce a toy scenario where there are 100 tables (too big to fit into the prompt)\n",
        "\n",
        "from sqlalchemy import create_engine, MetaData, Table, Column, String, Integer, select, column\n",
        "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
        "metadata_obj = MetaData()\n",
        "# create city SQL table\n",
        "table_name = \"city_stats\"\n",
        "city_stats_table = Table(\n",
        "    table_name,\n",
        "    metadata_obj,\n",
        "    Column(\"city_name\", String(16), primary_key=True),\n",
        "    Column(\"population\", Integer),\n",
        "    Column(\"country\", String(16), nullable=False),\n",
        ")\n",
        "\n",
        "metadata_obj.create_all(engine)\n",
        "# print tables\n",
        "metadata_obj.tables.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCyK-KwNSfKu"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import insert\n",
        "rows = [\n",
        "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
        "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
        "    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\n",
        "]\n",
        "for row in rows:\n",
        "    stmt = insert(city_stats_table).values(**row)\n",
        "    with engine.connect() as connection:\n",
        "        cursor = connection.execute(stmt)\n",
        "        connection.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csoWL2frSnGH"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as connection:\n",
        "    cursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\n",
        "    print(cursor.fetchall())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJLGZCHISn33"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "# We first show how to convert a Document into a set of Nodes, and insert into a DocumentStore.\n",
        "cities = ['Toronto', 'Berlin', 'Tokyo']\n",
        "wiki_docs = WikipediaReader().load_data(pages=cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SSuSCx8Sz5k"
      },
      "outputs": [],
      "source": [
        "# Build SQL Index\n",
        "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\n",
        "sql_index = SQLStructStoreIndex.from_documents(\n",
        "    [],\n",
        "    sql_database=sql_database,\n",
        "    table_name=\"city_stats\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip_GdJv-S3ah"
      },
      "outputs": [],
      "source": [
        "# Build Vector Index\n",
        "# build a separate vector index per city\n",
        "# You could also choose to define a single vector index across all docs, and annotate each chunk by metadata\n",
        "vector_indices = []\n",
        "for wiki_doc in wiki_docs:\n",
        "    vector_index = VectorStoreIndex.from_documents([wiki_doc])\n",
        "    vector_indices.append(vector_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pGh81hKS4n4"
      },
      "outputs": [],
      "source": [
        "# Define Query Engines, Set as Tools\n",
        "sql_query_engine = sql_index.as_query_engine()\n",
        "vector_query_engines = [index.as_query_engine() for index in vector_indices]\n",
        "from llama_index.tools.query_engine import QueryEngineTool\n",
        "\n",
        "\n",
        "sql_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=sql_query_engine,\n",
        "    description=(\n",
        "        'Useful for translating a natural language query into a SQL query over a table containing: '\n",
        "        'city_stats, containing the population/country of each city'\n",
        "    )\n",
        ")\n",
        "vector_tools = []\n",
        "for city, query_engine in zip(cities, vector_query_engines):\n",
        "    vector_tool = QueryEngineTool.from_defaults(\n",
        "        query_engine=query_engine,\n",
        "        description=f'Useful for answering semantic questions about {city}',\n",
        "    )\n",
        "    vector_tools.append(vector_tool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8DbPGr7S9BL"
      },
      "outputs": [],
      "source": [
        "# Define Router Query Engine\n",
        "from llama_index.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.selectors.llm_selectors import LLMSingleSelector\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=([sql_tool] + vector_tools)\n",
        ")\n",
        "response = query_engine.query('Which city has the highest population?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7U9dbyLTFOD"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vucFYIDwTHvJ"
      },
      "outputs": [],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecuSETa6TJpI"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query('Tell me about the historical museums in Berlin')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kgnn29Q4TLi6"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jol2lIpTMpa"
      },
      "outputs": [],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW9QmBH7emZA"
      },
      "source": [
        "# Hypothetical document embeddings (HyDE)\n",
        "\n",
        "Source: https://gpt-index.readthedocs.io/en/latest/examples/query_transformations/HyDEQueryTransformDemo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAGv8tgJepeZ"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.indices.query.query_transform import HyDEQueryTransform\n",
        "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
        "from IPython.display import Markdown, display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FkQ7Z5VerlN"
      },
      "outputs": [],
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader('llama_index/examples/paul_graham_essay/data').load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7Sqh4cne58j"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV0wioHHe7_C"
      },
      "outputs": [],
      "source": [
        "query_str = \"what did paul graham do after going to RISD\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KAqXB9RfGXv"
      },
      "outputs": [],
      "source": [
        "#Now, we use HyDEQueryTransform to generate a hypothetical document and use it for embedding lookup.\n",
        "hyde = HyDEQueryTransform(include_original=True)\n",
        "query_engine = index.as_query_engine()\n",
        "hyde_query_engine = TransformQueryEngine(query_engine, hyde)\n",
        "response = hyde_query_engine.query(query_str)\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvmDAfIJfMRp"
      },
      "outputs": [],
      "source": [
        "#In this example, HyDE improves output quality significantly, by hallucinating accurately what Paul Graham did after RISD (see below), and thus improving the embedding quality, and final output.\n",
        "query_bundle = hyde(query_str)\n",
        "hyde_doc = query_bundle.embedding_strs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9o10XhafShS"
      },
      "outputs": [],
      "source": [
        "hyde_doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QQxA5GUjjUn"
      },
      "source": [
        "# Use LlamaIndex with LangChain\n",
        "\n",
        "Source: https://github.com/jerryjliu/llama_index/blob/main/examples/langchain_demo/LangchainDemo.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opkGBl1njlZC"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "# Using LlamaIndex as a Callable Tool\n",
        "from langchain.agents import Tool\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "documents = SimpleDirectoryReader('llama_index/examples/paul_graham_essay/data').load_data()\n",
        "index = VectorStoreIndex.from_documents(documents=documents)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"LlamaIndex\",\n",
        "        func=lambda q: str(index.as_query_engine().query(q)),\n",
        "        description=\"useful for when you want to answer questions about the author. The input to this tool should be a complete english sentence.\",\n",
        "        return_direct=True\n",
        "    ),\n",
        "]\n",
        "\n",
        "# set Logging to DEBUG for more detailed outputs\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "agent_executor = initialize_agent(tools, llm, agent=\"conversational-react-description\", memory=memory)\n",
        "agent_executor.run(input=\"hi, i am bob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpTrF1qRj50c"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(input=\"What did the author do growing up?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNoWcbRmkmrI"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zXxLwcfkE4F"
      },
      "outputs": [],
      "source": [
        "# Using LlamaIndex as a memory module\n",
        "\n",
        "from langchain import OpenAI\n",
        "from langchain.llms import OpenAIChat\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "from llama_index import ListIndex\n",
        "from llama_index.langchain_helpers.memory_wrapper import GPTIndexChatMemory\n",
        "index = ListIndex([])\n",
        "# set Logging to DEBUG for more detailed outputs\n",
        "# NOTE: you can also use a conversational chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd0hxDjSkMsI"
      },
      "outputs": [],
      "source": [
        "memory = GPTIndexChatMemory(\n",
        "    index=index,\n",
        "    memory_key=\"chat_history\",\n",
        "    query_kwargs={\"response_mode\": \"compact\"},\n",
        "    # return_source returns source nodes instead of querying index\n",
        "    return_source=True,\n",
        "    # return_messages returns context in message format\n",
        "    return_messages=True\n",
        ")\n",
        "llm = OpenAIChat(temperature=0)\n",
        "# llm=OpenAI(temperature=0)\n",
        "agent_executor = initialize_agent([], llm, agent=\"conversational-react-description\", memory=memory)\n",
        "agent_executor.run(input=\"hi, i am bob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg9DjiRwkOMF"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(input=\"what's my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35UJTZ7YkRQS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}